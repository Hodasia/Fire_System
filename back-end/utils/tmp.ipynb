{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "from tqdm import trange\n",
    "import models.simplevit as simplevit\n",
    "import models.unet as unet\n",
    "import utils.funcs as funcs\n",
    "import utils.norm as norm\n",
    "import utils.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "h,w=2025,1350\n",
    "ks=15\n",
    "skip=ks\n",
    "cl=funcs.chunk_list(h,w,ks,skip)\n",
    "output_channel = 9\n",
    "thrd=0.5\n",
    "batch_num=10\n",
    "c21_thrd, c22_thrd=1.0, 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (conv1): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(9, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): GroupNorm(2, 32, eps=1e-05, affine=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (conv2): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): GroupNorm(4, 64, eps=1e-05, affine=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (conv3): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (conv4): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): GroupNorm(16, 256, eps=1e-05, affine=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (conv_u): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): GroupNorm(16, 256, eps=1e-05, affine=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (upconv4): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): GroupNorm(16, 256, eps=1e-05, affine=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (upconv3): up_conv_block(\n",
       "    (up): Sequential(\n",
       "      (0): ConvTranspose2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (upconv2): up_conv_block(\n",
       "    (up): Sequential(\n",
       "      (0): ConvTranspose2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): GroupNorm(4, 64, eps=1e-05, affine=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (upconv1): up_conv_block(\n",
       "    (up): Sequential(\n",
       "      (0): ConvTranspose2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): GroupNorm(2, 32, eps=1e-05, affine=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (conv): Sequential(\n",
       "    (0): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('device', device)\n",
    "\n",
    "# 分类模型加载\n",
    "model_simplevit = simplevit.SimpleViT()\n",
    "checkpoint_simplevit = torch.load('./weights/simpleViT_1.pth')\n",
    "model_simplevit.load_state_dict(checkpoint_simplevit['sd'])\n",
    "model_simplevit.cuda()\n",
    "model_simplevit.eval()\n",
    "\n",
    "# 分割模型加载\n",
    "model_unet = unet.UNet()\n",
    "checkpoint_unet = torch.load('./weights/unet_5.pth')\n",
    "model_unet.load_state_dict(checkpoint_unet['sd'])\n",
    "model_unet.cuda()\n",
    "model_unet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1215/1215 [06:43<00:00,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12150, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "img_path = \"D:/data/20220011140.npz\"\n",
    "data = np.load(img_path)\n",
    "img = data['arr_0'][:, 0:h, 0:w]\n",
    "# origin_img = img[output_channel]\n",
    "\n",
    "\n",
    "# 切成子图\n",
    "sub_img = []\n",
    "for c in cl:\n",
    "    d=img[:, c[0]:c[1],c[2]:c[3]]\n",
    "    sub_img.append(d)\n",
    "sub_img = np.asarray(sub_img)\n",
    "\n",
    "\n",
    "# 分类\n",
    "x_classify = sub_img[:, :9]\n",
    "x_classify = norm.nor2(x_classify, 'classify')\n",
    "cnt = math.ceil(x_classify.shape[0]/batch_num)\n",
    "new_x_classify = np.array_split(x_classify, cnt, axis=0)\n",
    "\n",
    "output_classify = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in trange(len(new_x_classify)):\n",
    "        input_classify = new_x_classify[i]\n",
    "        input_classify = torch.Tensor(input_classify).cuda()\n",
    "\n",
    "        pred_classify = model_simplevit(input_classify)\n",
    "        pred_classify=pred_classify.detach().cpu().numpy()\n",
    "        pred_classify[pred_classify<=thrd]=0 \n",
    "        pred_classify[pred_classify>thrd]=1\n",
    "\n",
    "        output_classify.extend(pred_classify)\n",
    "\n",
    "output_classify = np.asarray(output_classify)\n",
    "print(output_classify.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分割\n",
    "indices_seg = np.where(output_classify == 1)[0] # 只对火点子图进行分割\n",
    "x_seg = sub_img[indices_seg][:, :9]\n",
    "y_seg = sub_img[indices_seg][:, -1]\n",
    "y_seg[y_seg<80]=0\n",
    "y_seg[y_seg>=80]=1\n",
    "y_seg = np.expand_dims(y_seg, axis=1)\n",
    "\n",
    "output_seg = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    input_seg = norm.nor2(x_seg, 'seg')\n",
    "    input_seg = torch.Tensor(input_seg).cuda()\n",
    "            \n",
    "    pred_seg = model_unet(input_seg)\n",
    "    pred_seg=pred_seg.detach().cpu().numpy()\n",
    "    pred_seg[pred_seg<=thrd]=0\n",
    "    pred_seg[pred_seg>thrd]=1\n",
    "    output_seg.extend(pred_seg)\n",
    "output_seg = np.asarray(output_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_fire = 0\n",
    "tp, fp, tn, fn=0, 0, 0, 0\n",
    "\n",
    "# 还原图像\n",
    "# 创建一个全零数组，形状与原始图像相同\n",
    "restored_img = np.zeros((h,w))\n",
    "\n",
    "# 将 sub_img 中的子图像放回原始图像对应的位置\n",
    "for i, c in enumerate(cl):\n",
    "    if i in indices_seg:\n",
    "        restored_sub = output_seg[cnt_fire].reshape((15, 15))\n",
    "        cnt_fire += 1\n",
    "    else:\n",
    "        restored_sub = np.zeros((15, 15))\n",
    "    restored_img[c[0]:c[1], c[2]:c[3]] = restored_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 2025, 1350)\n",
      "(2025, 1350)\n",
      "(2025, 1350)\n",
      "0.8641975308641975 0.8085808580858086 0.928030303030303 0.7608695652173912 0.999943667123914\n"
     ]
    }
   ],
   "source": [
    "img_path = \"D:/data/20220011140.npz\"\n",
    "data = np.load(img_path)\n",
    "img = data['arr_0'][:, 0:h, 0:w]\n",
    "print(img.shape)\n",
    "con = img[-1, :]\n",
    "con[con < 80] = 0\n",
    "con[con >= 80] = 1\n",
    "print(con.shape)\n",
    "print(restored_img.shape)\n",
    "tp,fp,tn,fn= metrics.cal_hit(restored_img,con)\n",
    "f1, p, r, iou, acc = metrics.cal_score(tp, fp, tn, fn)\n",
    "print(f1, p, r, iou, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1215/1215 [00:18<00:00, 64.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2025, 1350)\n",
      "(2025, 1350)\n",
      "0.7937007874015748 0.675603217158177 0.9618320610687023 0.6579634464751958 0.9999520804755373\n"
     ]
    }
   ],
   "source": [
    "data_path = './processor/final/data/'\n",
    "img_file = '20220041350.npz'\n",
    "img_id = os.path.splitext(img_file)[0]\n",
    "img_path = os.path.join(data_path, img_file)\n",
    "data = np.load(img_path)\n",
    "img = data['arr_0'][:, 0:h, 0:w]\n",
    "# origin_img = img[output_channel]\n",
    "\n",
    "\n",
    "# 切成子图\n",
    "sub_img = []\n",
    "for c in cl:\n",
    "    d=img[:, c[0]:c[1],c[2]:c[3]]\n",
    "    sub_img.append(d)\n",
    "sub_img = np.asarray(sub_img)\n",
    "\n",
    "# 分类\n",
    "# x_cls = sub_img[:, :9]\n",
    "# output_cls = []\n",
    "\n",
    "# # 阈值初筛\n",
    "# for i in range(sub_img.shape[0]):\n",
    "#     p_c21, p_c22 = np.max(sub_img[i, 4]), np.max(sub_img[i, 5])\n",
    "#     if not (p_c21 >= c21_thrd and p_c22 >= c22_thrd):\n",
    "#         output_cls.extend([0])\n",
    "#     else:\n",
    "#         output_cls.extend([1])\n",
    "\n",
    "# output_cls = np.asarray(output_cls)\n",
    "# print(output_cls.shape)\n",
    "\n",
    "# # 送入分类模型进行进一步筛选\n",
    "# indices_cls = np.where(output_cls == 1)[0]\n",
    "# print(indices_cls.shape)\n",
    "# new_tmp = norm.nor2(x_cls[indices_cls], 'classify')\n",
    "# cnt = math.ceil(new_tmp.shape[0]/batch_num)\n",
    "# new_x_cls = np.array_split(new_tmp, cnt, axis=0)\n",
    "# output = []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for i in trange(len(new_x_cls)):\n",
    "#         input_cls = new_x_cls[i]\n",
    "#         input_cls = torch.Tensor(input_cls).cuda()\n",
    "\n",
    "#         pred_cls = model_simplevit(input_cls)\n",
    "#         pred_cls = pred_cls.detach().cpu().numpy()\n",
    "#         pred_cls[pred_cls<=thrd]=0\n",
    "#         pred_cls[pred_cls>thrd]=1\n",
    "#         output.extend(pred_cls)\n",
    "# output = np.asarray(output)\n",
    "# print(output.shape)\n",
    "\n",
    "# output_cls = output_cls.reshape(-1,1)\n",
    "# output_cls[indices_cls] = output\n",
    "\n",
    "# 分割\n",
    "# indices_seg = np.where(output_cls == 1)[0] # 只对火点子图进行分割\n",
    "# x_seg = sub_img[indices_seg][:, :9]\n",
    "# y_seg = sub_img[indices_seg][:, -1]\n",
    "\n",
    "x_seg = sub_img[:, :9]\n",
    "new_tmp = norm.nor2(x_seg, 'seg')\n",
    "cnt = math.ceil(new_tmp.shape[0]/batch_num)\n",
    "new_x_seg = np.array_split(new_tmp, cnt, axis=0)\n",
    "\n",
    "y_seg = sub_img[:, -1]\n",
    "y_seg[y_seg<80]=0\n",
    "y_seg[y_seg>=80]=1\n",
    "y_seg = np.expand_dims(y_seg, axis=1)\n",
    "\n",
    "output_seg = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in trange(len(new_x_seg)):\n",
    "        # input_seg = norm.nor2(x_seg, 'seg')\n",
    "        input_seg = new_x_seg[i]\n",
    "        input_seg = torch.Tensor(input_seg).cuda()\n",
    "                \n",
    "        pred_seg = model_unet(input_seg)\n",
    "        pred_seg=pred_seg.detach().cpu().numpy()\n",
    "        pred_seg[pred_seg<=thrd]=0\n",
    "        pred_seg[pred_seg>thrd]=1\n",
    "        output_seg.extend(pred_seg)\n",
    "output_seg = np.asarray(output_seg)\n",
    "\n",
    "cnt_fire = 0\n",
    "tp, fp, tn, fn=0, 0, 0, 0\n",
    "\n",
    "# 还原图像\n",
    "# 创建一个全零数组，形状与原始图像相同\n",
    "restored_img = np.zeros((h,w))\n",
    "\n",
    "# 将 sub_img 中的子图像放回原始图像对应的位置\n",
    "# for i, c in enumerate(cl):\n",
    "#     if i in indices_seg:\n",
    "#         restored_sub = output_seg[cnt_fire].reshape((15, 15))\n",
    "#         cnt_fire += 1\n",
    "#     else:\n",
    "#         restored_sub = np.zeros((15, 15))\n",
    "#     restored_img[c[0]:c[1], c[2]:c[3]] = restored_sub\n",
    "for i, c in enumerate(cl):\n",
    "    restored_img[c[0]:c[1], c[2]:c[3]] = output_seg[cnt_fire]\n",
    "    cnt_fire += 1\n",
    "\n",
    "con = img[-1, :]\n",
    "con[con < 80] = 0\n",
    "con[con >= 80] = 1\n",
    "print(con.shape)\n",
    "print(restored_img.shape)\n",
    "tp,fp,tn,fn= metrics.cal_hit(restored_img,con)\n",
    "f1, p, r, iou, acc = metrics.cal_score(tp, fp, tn, fn)\n",
    "print(f1, p, r, iou, acc)\n",
    "\n",
    "# file:20220021045 tp:79 fp:34 tn:15179 fn:8 f1:0.790000 p:0.699115 r:0.908046 iou:0.652893 acc:0.997255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\fire_system\\back-end\\tmp.ipynb Cell 9\u001b[0m line \u001b[0;36m<cell line: 31>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/fire_system/back-end/tmp.ipynb#X23sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m data \u001b[39m=\u001b[39m {\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/fire_system/back-end/tmp.ipynb#X23sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mid\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m1\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/fire_system/back-end/tmp.ipynb#X23sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtp\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m2\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/fire_system/back-end/tmp.ipynb#X23sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39macc\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m10\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/fire_system/back-end/tmp.ipynb#X23sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     }\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/fire_system/back-end/tmp.ipynb#X23sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# # 将数据写入 JSON 文件\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/fire_system/back-end/tmp.ipynb#X23sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# with open(\"score.json\", \"w\") as json_file:\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/fire_system/back-end/tmp.ipynb#X23sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m#     json.dump(data, json_file, indent=4)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/fire_system/back-end/tmp.ipynb#X23sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39mprint\u001b[39m(data\u001b[39m.\u001b[39;49mid)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'id'"
     ]
    }
   ],
   "source": [
    "# data = {\n",
    "#         \"id\": img_id,\n",
    "#         \"tp\": tp,\n",
    "#         \"fp\": fp,\n",
    "#         \"tn\": tn,\n",
    "#         \"fn\": fn,\n",
    "#         \"f1\": f1,\n",
    "#         \"p\": p,\n",
    "#         \"r\": r,\n",
    "#         \"iou\": iou,\n",
    "#         \"acc\": acc\n",
    "#     }\n",
    "\n",
    "data = {\n",
    "        \"id\": 1,\n",
    "        \"tp\": 2,\n",
    "        \"fp\": 3,\n",
    "        \"tn\": 4,\n",
    "        \"fn\": 5,\n",
    "        \"f1\": 6,\n",
    "        \"p\": 7,\n",
    "        \"r\": 8,\n",
    "        \"iou\": 9,\n",
    "        \"acc\": 10\n",
    "    }\n",
    "\n",
    "\n",
    "# # 将数据写入 JSON 文件\n",
    "# with open(\"score.json\", \"w\") as json_file:\n",
    "#     json.dump(data, json_file, indent=4)\n",
    "print(data.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\fire_system\\back-end\\tmp.ipynb Cell 10\u001b[0m line \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/fire_system/back-end/tmp.ipynb#X24sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m img_info  \u001b[39m# 返回字典\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/fire_system/back-end/tmp.ipynb#X24sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m img_info \u001b[39m=\u001b[39m read_variables(img_id)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/fire_system/back-end/tmp.ipynb#X24sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mprint\u001b[39m(img_info\u001b[39m.\u001b[39;49mid)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'id'"
     ]
    }
   ],
   "source": [
    "def read_variables(img_id):\n",
    "    with open('score.json', 'r') as json_file:  # 打开 JSON 文件\n",
    "        data = json.load(json_file)  # 加载 JSON 数据\n",
    "        img_info = {}  # 创建一个空字典\n",
    "        for entry in data:  # 迭代 JSON 数据中的每个条目\n",
    "            if entry['id'] == img_id:  # 检查条目的 ID 是否与所需的 ID 匹配\n",
    "                img_info = entry['info']  # 提取相关信息\n",
    "                break\n",
    "\n",
    "    return img_info  # 返回字典\n",
    "\n",
    "img_info = read_variables(img_id)\n",
    "print(img_info.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tp': 169.0, 'fp': 47.0, 'tn': 32404.0, 'fn': 5.0, 'f1': 0.866667, 'p': 0.782407, 'r': 0.971264, 'iou': 0.764706, 'acc': 0.998406}\n"
     ]
    }
   ],
   "source": [
    "def read_variables(img_id):\n",
    "    with open('./processor/score.txt', 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        img_info = {}  # 创建一个空字典\n",
    "        for line in lines:\n",
    "            pairs = line.split()\n",
    "            cnt = 0\n",
    "            for pair in pairs:\n",
    "                name, value = pair.split(':')\n",
    "                if cnt == 0:\n",
    "                    cnt += 1\n",
    "                    file_id = value\n",
    "                else:\n",
    "                    img_info[name] = float(value)\n",
    "\n",
    "            if file_id == img_id:\n",
    "                break\n",
    "    return img_info  # 返回字典\n",
    "\n",
    "img_info = read_variables('20220011320')\n",
    "print(img_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "元素值为0的个数: 2733675\n",
      "元素值为1的个数: 75\n",
      "0.0027435594940876293\n"
     ]
    }
   ],
   "source": [
    "data = np.load('D:/data/20220011815.npz')\n",
    "img = data['arr_0'][:, 0:h, 0:w]\n",
    "con = img[10]\n",
    "con[con<80]=0\n",
    "con[con>=80]=1\n",
    "print(con.max())\n",
    "count_zero = (con.size - np.count_nonzero(con))\n",
    "count_one = np.count_nonzero(con)\n",
    "\n",
    "print(\"元素值为0的个数:\", count_zero)\n",
    "print(\"元素值为1的个数:\", count_one)\n",
    "print(100 * (count_one/count_zero))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "img_id='20220011815'\n",
    "img_id2='20020011850'\n",
    "tp=66\n",
    "fp=12\n",
    "tn=2733675\n",
    "fn=9\n",
    "f1=0.88\n",
    "p=0.92\n",
    "r=0.86\n",
    "iou=0.77\n",
    "acc=0.99\n",
    "\n",
    "dict_list = []\n",
    "\n",
    "# 假设img_info是已经定义好的字典\n",
    "img_info1 = {'id': img_id, 'tp': int(tp), 'fp': int(fp), 'tn': int(tn), 'fn': int(fn),\n",
    "        'f1': round(f1, 4), 'p': round(p, 4), 'r': round(r, 4), 'iou': round(iou, 4), 'acc': round(acc, 4)}\n",
    "dict_list.append(img_info1)\n",
    "\n",
    "img_info2 = {'id': img_id2, 'tp': int(tp), 'fp': int(fp), 'tn': int(tn), 'fn': int(fn),\n",
    "        'f1': round(f1, 4), 'p': round(p, 4), 'r': round(r, 4), 'iou': round(iou, 4), 'acc': round(acc, 4)}\n",
    "dict_list.append(img_info2)\n",
    "\n",
    "\n",
    "# 定义文件名\n",
    "file_name = 'img_info.json'\n",
    "\n",
    "# 将字典写入JSON文件\n",
    "with open(file_name, 'w') as json_file:\n",
    "    json.dump(dict_list, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "找到对应的字典数据： {'id': '20020011850', 'tp': 66, 'fp': 12, 'tn': 2733675, 'fn': 9, 'f1': 0.88, 'p': 0.92, 'r': 0.86, 'iou': 0.77, 'acc': 0.99}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def read_img_info(img_id, file_name):\n",
    "    # 读取JSON文件中的数据\n",
    "    with open(file_name, 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "    \n",
    "    # 根据img_id查找对应的字典数据\n",
    "    img_info = None\n",
    "    for item in data:\n",
    "        if item['id'] == img_id:\n",
    "            img_info = item\n",
    "            break\n",
    "    \n",
    "    return img_info\n",
    "\n",
    "# 定义文件名\n",
    "file_name = 'img_info.json'\n",
    "\n",
    "# 定义要查找的img_id\n",
    "target_img_id = '20020011850'\n",
    "\n",
    "# 读取对应img_id的字典数据\n",
    "result = read_img_info(target_img_id, file_name)\n",
    "\n",
    "if result:\n",
    "    print(\"找到对应的字典数据：\", result)\n",
    "else:\n",
    "    print(\"未找到对应的字典数据。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot load file containing pickled data when allow_pickle=False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\fire_system\\back-end\\tmp.ipynb Cell 15\u001b[0m line \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/fire_system/back-end/tmp.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/fire_system/back-end/tmp.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m data_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m./processor/final/results/20220061335.png\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/fire_system/back-end/tmp.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m img \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mload(data_path)\n",
      "File \u001b[1;32me:\\Python\\miniconda\\envs\\pytorch\\lib\\site-packages\\numpy\\lib\\npyio.py:438\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    436\u001b[0m     \u001b[39m# Try a pickle\u001b[39;00m\n\u001b[0;32m    437\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_pickle:\n\u001b[1;32m--> 438\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot load file containing pickled data \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    439\u001b[0m                          \u001b[39m\"\u001b[39m\u001b[39mwhen allow_pickle=False\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    440\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    441\u001b[0m         \u001b[39mreturn\u001b[39;00m pickle\u001b[39m.\u001b[39mload(fid, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_kwargs)\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot load file containing pickled data when allow_pickle=False"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "data_path = './processor/final/results/20220061335.png'\n",
    "img = np.load(data_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
